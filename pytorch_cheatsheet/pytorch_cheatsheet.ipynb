{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bee64cb2-8555-4239-babc-8f0d249bce19",
   "metadata": {},
   "source": "<a href=\"https://colab.research.google.com/github/19z/pytorch-deep-learning/blob/main/extras/pytorch_cheatsheet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"在 Colab 中打开\"/></a>"
  },
  {
   "cell_type": "markdown",
   "id": "b721b6b3-bf94-4f8f-9aae-9fa119962b1d",
   "metadata": {},
   "source": [
    "# PyTorch 速查表\n",
    "\n",
    "PyTorch 中一些最常用的命令/设置。\n",
    "\n",
    "> **注意：** 获取 PyTorch 特定函数和用例帮助的最佳方式之一是搜索“pytorch 如何构建卷积神经网络”或“pytorch 变换器层”或“pytorch 损失函数”。我经常这样做。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee9c36f-3fd9-42b8-a5b6-a5a4de1e5cdd",
   "metadata": {},
   "source": [
    "## 导入\n",
    "\n",
    "你可以通过[PyTorch 安装页面](https://pytorch.org/get-started/locally/)在不同平台上安装 PyTorch。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98cf25ad-8e15-4692-a496-dc69b83a2f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.13.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check the version\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e369e44-8cea-4171-87f4-93bf421155c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.modules.linear.Linear'>\n"
     ]
    }
   ],
   "source": [
    "# Can also import the common abbreviation \"nn\" for \"Neural Networks\"\n",
    "from torch import nn\n",
    "\n",
    "# Almost everything in PyTorch is called a \"Module\" (you build neural networks by stacking together Modules)\n",
    "this_is_a_module = nn.Linear(in_features=1,\n",
    "                             out_features=1)\n",
    "print(type(this_is_a_module))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89b206a-6869-4d33-b313-e952aef82adf",
   "metadata": {},
   "source": [
    "### 数据导入\n",
    "\n",
    "由于机器学习的大部分工作是发现数据中的模式，因此了解如何在 PyTorch 中处理数据集是很有必要的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a6cf16f-f713-4a5a-8666-a622695eb612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PyTorch Dataset (you can store your data here) and DataLoader (you can load your data here)\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58418977-bdb1-4dfb-858c-3d99e5d0ef77",
   "metadata": {},
   "source": [
    "## 创建张量\n",
    "\n",
    "PyTorch 的主要用途之一是用于加速深度学习计算。\n",
    "\n",
    "而深度学习通常涉及对大型张量（庞大、多维的数字集合）的操作。\n",
    "\n",
    "PyTorch 提供了多种创建张量的方法。\n",
    "\n",
    "> **注意：** 关于使用 PyTorch 创建张量的更全面概述，请参阅 [00. PyTorch 基础](https://www.learnpytorch.io/00_pytorch_fundamentals/)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce6c9952-5783-4ade-8c92-06b4393139ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a single number tensor (scalar)\n",
    "scalar = torch.tensor(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3f4f286-a8e6-4db0-8d5e-0c7aaf3b7c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random tensor\n",
    "random_tensor = torch.rand(size=(3, 4)) # this will create a tensor of size 3x4 but you can manipulate the shape how you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf17bde1-c03d-4f7c-ab2a-d24f59161cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiply two random tensors\n",
    "random_tensor_1 = torch.rand(size=(3, 4))\n",
    "random_tensor_2 = torch.rand(size=(3, 4))\n",
    "random_tensor_3 = random_tensor_1 * random_tensor_2 # PyTorch has support for most math operators in Python (+, *, -, /)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f51efe1-609a-40c0-94a2-1f6c816599ef",
   "metadata": {},
   "source": [
    "## 领域库\n",
    "\n",
    "根据您正在处理的具体问题，PyTorch 提供了几个领域库。\n",
    "\n",
    "- **[TorchVision](https://pytorch.org/vision/stable/index.html)** — PyTorch 的计算机视觉库。\n",
    "- **[TorchText](https://pytorch.org/text/stable/index.html)** — PyTorch 内置的文本领域库。\n",
    "- **[TorchAudio](https://pytorch.org/audio/stable/index.html)** — PyTorch 的音频领域库。\n",
    "- **[TorchRec](https://pytorch.org/torchrec/)** — PyTorch 最新的内置领域库，用于通过深度学习驱动推荐引擎。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966a5d29-d2f4-4089-b3a7-6b400f695d20",
   "metadata": {},
   "source": [
    "### 计算机视觉\n",
    "\n",
    "> **注意：** 有关 PyTorch 中计算机视觉的深入概述，请参阅 [03. PyTorch 计算机视觉](https://www.learnpytorch.io/03_pytorch_computer_vision/)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5353bfa2-d950-4f23-98c3-d29ff7c85e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base computer vision library\n",
    "import torchvision\n",
    "\n",
    "# Other components of TorchVision (premade datasets, pretrained models and image transforms)\n",
    "from torchvision import datasets, models, transforms "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d044f35e-068f-4664-a16c-b3150a842ce2",
   "metadata": {},
   "source": [
    "### 文本与自然语言处理（NLP）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "328b5026-fb0e-42f6-a50f-e4171a379c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base text and natural language processing library\n",
    "import torchtext\n",
    "\n",
    "# Other components of TorchText (premade datasets, pretrained models and text transforms)\n",
    "from torchtext import datasets, models, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2409d640-a768-4423-a37c-3f4f2472b319",
   "metadata": {},
   "source": [
    "### 音频与语音"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "956edd5a-291b-41d5-b7fa-507a171171dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base audio and speech processing library\n",
    "import torchaudio\n",
    "\n",
    "# Other components of TorchAudio (premade datasets, pretrained models and text transforms)\n",
    "from torchaudio import datasets, models, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf19cae-f18b-4bb9-af99-56725a739df7",
   "metadata": {},
   "source": [
    "### 推荐系统\n",
    "\n",
    "> **注意：** 该库目前处于测试版本，请参阅 [GitHub 页面进行安装](https://github.com/pytorch/torchrec#installation)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddb24f63-13c9-406c-9608-f66042a99f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Base recommendation system library \n",
    "# import torchrec\n",
    "\n",
    "# # Other components of TorchRec\n",
    "# from torchrec import datasets, models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dc7202-271a-4473-94fc-4945319bda37",
   "metadata": {},
   "source": [
    "## 设备无关代码（使用 PyTorch 在 CPU、GPU 或 MPS 上运行）\n",
    "\n",
    "深度学习的大部分工作涉及对张量进行计算。\n",
    "\n",
    "与 CPU（中央处理单元）相比，在 GPU（图形处理单元，通常来自 NVIDIA）上进行张量计算通常会快得多。\n",
    "\n",
    "MPS 代表 \"Metal Performance Shader\"，这是 Apple 的 GPU（如 M1、M1 Pro、M2 等）。\n",
    "\n",
    "建议在您可用的最快的硬件上进行训练，通常的优先顺序是：NVIDIA GPU（`\"cuda\"`）> MPS 设备（`\"mps\"`）> CPU（`\"cpu\"`）。\n",
    "\n",
    "* 关于如何让 [PyTorch 在 NVIDIA GPU（使用 CUDA）上运行](https://pytorch.org/docs/stable/cuda.html)，请参阅 [00. PyTorch 基础部分 2：让 PyTorch 在 GPU 上运行](https://www.learnpytorch.io/00_pytorch_fundamentals/#2-getting-pytorch-to-run-on-the-gpu)。\n",
    "* 关于使用 MPS 后端运行 PyTorch（在 Mac GPU 上运行 PyTorch）的更多信息，[请参阅 PyTorch 文档](https://pytorch.org/docs/stable/notes/mps.html)。\n",
    "\n",
    "> **注意：** 建议在开始工作流程时设置设备无关代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "081f561d-63f7-4609-86eb-868750eb8b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Setup device-agnostic code \n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\" # NVIDIA GPU\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\" # Apple GPU\n",
    "else:\n",
    "    device = \"cpu\" # Defaults to CPU if NVIDIA GPU/Apple GPU aren't available\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208f1f37-470f-486a-9a71-b7128ae295a9",
   "metadata": {},
   "source": [
    "### 将张量发送到目标设备\n",
    "\n",
    "你可以通过 `.to(\"device_name\")` 方法将 PyTorch 中的对象（模型和张量）移动到不同的设备上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7dc6c29a-5d0a-45e1-9dde-547356e1366e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "mps:0\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor \n",
    "x = torch.tensor([1, 2, 3]) \n",
    "print(x.device) # defaults to CPU \n",
    "\n",
    "# Send tensor to target device\n",
    "x = x.to(device)\n",
    "print(x.device) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d27d062-281b-4628-9374-c276640aceb8",
   "metadata": {},
   "source": [
    "## 设置随机种子\n",
    "\n",
    "在机器学习和深度学习中，很多情况下需要从张量中获取随机数，然后对这些随机数进行处理，以发现或表示真实数据中的模式。\n",
    "\n",
    "然而，有时你希望这种随机性是“可复现”的。\n",
    "\n",
    "为此，你可以设置随机种子，更多信息请参见[可复现性（试图消除随机性）](https://www.learnpytorch.io/00_pytorch_fundamentals/#reproducibility-trying-to-take-the-random-out-of-random)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de557ce2-60df-4945-a57a-a8dc5e7de756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor A:\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "\n",
      "Tensor B:\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "\n",
      "Does Tensor A equal Tensor B? (anywhere)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True],\n",
       "        [True, True, True, True],\n",
       "        [True, True, True, True]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Set the random seed (you can set this to any number you like, it will \"flavour\"\n",
    "# the randomness with that number.\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Create two random tensors\n",
    "random_tensor_A = torch.rand(3, 4)\n",
    "\n",
    "torch.manual_seed(42) # set the seed again (try commenting this out and see what happens)\n",
    "random_tensor_B = torch.rand(3, 4)\n",
    "\n",
    "print(f\"Tensor A:\\n{random_tensor_A}\\n\")\n",
    "print(f\"Tensor B:\\n{random_tensor_B}\\n\")\n",
    "print(f\"Does Tensor A equal Tensor B? (anywhere)\")\n",
    "random_tensor_A == random_tensor_B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ea594e-6ae6-4637-97bb-e52cd537df64",
   "metadata": {},
   "source": [
    "你也可以在GPU（CUDA设备）上设置随机种子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2499098-9311-40b2-8ff3-63d433064aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed on GPU\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efd5fba-9578-481b-850e-a968ade7700a",
   "metadata": {},
   "source": [
    "## 神经网络\n",
    "\n",
    "PyTorch 提供了一个非常全面的预构建神经网络组件库（在 PyTorch 生态系统中，这些组件通常被称为“模块”）。\n",
    "\n",
    "从基本层面来看，神经网络是由一系列*层*组成的堆栈。每一层对输入执行某种操作并产生输出。\n",
    "\n",
    "这些层如何堆叠在一起将取决于你正在解决的问题。\n",
    "\n",
    "机器学习领域最活跃的研究领域之一是如何将神经网络层堆叠在一起（对此的最佳答案不断变化）。\n",
    "\n",
    "PyTorch 中绝大多数神经网络组件都包含在 [`torch.nn` 包](https://pytorch.org/docs/stable/nn.html) 中（`nn` 是 neural networks 的缩写）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "888b039b-c4ad-4f47-bad7-75ac8ca7db12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497528d9-9fef-4323-8438-b7a298ed7ea3",
   "metadata": {},
   "source": [
    "### 线性层\n",
    "\n",
    "PyTorch 提供了几种内置的[线性层](https://pytorch.org/docs/stable/nn.html#linear-layers)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79047b27-3752-4e36-b7a9-a8e95bac20c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a linear layer with 10 in features and out features\n",
    "linear_layer = nn.Linear(in_features=10,\n",
    "                         out_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4972c605-39b4-43e4-aba4-02d9527cbbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an Identity layer\n",
    "identity_layer = nn.Identity()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9115ee4f-67a1-4adb-92e1-7604ccbb4b62",
   "metadata": {},
   "source": [
    "### 卷积层（用于构建卷积神经网络或CNN）\n",
    "\n",
    "PyTorch 提供了[多种内置的卷积层](https://pytorch.org/docs/stable/nn.html#convolution-layers)。\n",
    "\n",
    "卷积层的命名通常遵循 `torch.nn.ConvXd` 的格式，其中 `X` 可以是 `1`、`2` 或 `3`。\n",
    "\n",
    "`X` 的值表示卷积操作将涉及的维度数量，例如，`1` 表示单维文本，`2` 表示二维图像（高度 x 宽度），`3` 表示三维对象，如视频（视频被视为一系列具有时间维度的图像，高度 x 宽度 x 时间）。\n",
    "\n",
    "> **注意：** 你可以在[03. PyTorch 计算机视觉部分 7.2：构建卷积神经网络（CNN）](https://www.learnpytorch.io/03_pytorch_computer_vision/#7-model-2-building-a-convolutional-neural-network-cnn)中查看更多关于使用 PyTorch 构建计算机视觉卷积神经网络的内容。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "882a8c21-cc87-4ebe-9a03-68f9765647c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Conv1d layer (often used for text with a singular dimension)\n",
    "conv1d = nn.Conv1d(in_channels=1,\n",
    "                   out_channels=10,\n",
    "                   kernel_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93d96033-75e4-4695-ad39-c488bb0a5038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Conv2d layer (often used for images with Height x Width dimensions)\n",
    "conv2d = nn.Conv2d(in_channels=3, # 3 channels for color images (red, green, blue)\n",
    "                   out_channels=10,\n",
    "                   kernel_size=3)                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0b697f0-b80b-4dc7-a7d9-b771dad6c171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Conv3d layer (often used for video with Height x Width x Time dimensions)\n",
    "conv3d = nn.Conv3d(in_channels=3,\n",
    "                   out_channels=10,\n",
    "                   kernel_size=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6042dabb-9f18-4cd1-916b-b0d864048b7e",
   "metadata": {},
   "source": [
    "### Transformer层（用于构建Transformer模型）\n",
    "\n",
    "PyTorch内置了Transformer层，这些层在论文[Attention Is All You Need](https://arxiv.org/abs/1706.03762)中有详细描述。\n",
    "\n",
    "使用内置的PyTorch Transformer层的好处是，得益于[PyTorch的BetterTransformer](https://pytorch.org/blog/a-better-transformer-for-fast-transformer-encoder-inference/)，可能会带来潜在的速度提升。\n",
    "\n",
    "> **注意：** 你可以在[08. PyTorch论文复现](https://www.learnpytorch.io/08_pytorch_paper_replicating/)中看到如何使用PyTorch的内置Transformer层构建Vision Transformer。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0bcab8b8-defc-4d8c-8d75-c7826f200dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Transformer model (model based on the paper \"Attention Is All You Need\" - https://arxiv.org/abs/1706.03762)\n",
    "transformer_model = nn.Transformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba384ef7-d6f4-4969-80da-f477634ea96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a single Transformer encoder cell\n",
    "transformer_encoder = nn.TransformerEncoderLayer(d_model=768, # embedding dimension\n",
    "                                                 nhead=12) # number of attention heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e761141-0967-4804-a71b-03994132f865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack together Transformer encoder cells\n",
    "transformer_encoder_stack = nn.TransformerEncoder(encoder_layer=transformer_encoder, # from above\n",
    "                                                  num_layers=6) # 6 Transformer encoders stacked on top of each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "afdc3a0f-b4c4-47a2-ab29-999e66b5ed08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a single Transformer decoder cell\n",
    "transformer_decoder = nn.TransformerDecoderLayer(d_model=768,\n",
    "                                                 nhead=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0bf68ba3-2f4b-454f-a5fe-3707bf52fa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack together Transformer decoder cells\n",
    "transformer_decoder_stack = nn.TransformerDecoder(decoder_layer=transformer_decoder, # from above\n",
    "                                                  num_layers=6) # 6 Transformer decoders stacked on top of each other"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6397f85-2263-47b1-b720-c3d46bf0eaef",
   "metadata": {},
   "source": [
    "### 循环层（用于构建循环神经网络或RNN）\n",
    "\n",
    "PyTorch内置支持[循环神经网络层](https://pytorch.org/docs/stable/nn.html#recurrent-layers)，例如[长短期记忆（LSTM）](https://en.wikipedia.org/wiki/Long_short-term_memory)和[门控循环单元（GRU）](https://en.wikipedia.org/wiki/Gated_recurrent_unit)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aabbfdc0-3673-42c8-b075-62664cc4be85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a single LSTM cell\n",
    "lstm_cell = nn.LSTMCell(input_size=10, # can adjust as necessary\n",
    "                        hidden_size=10) # can adjust as necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df67845c-55b5-4e67-9058-699075644b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack together LSTM cells\n",
    "lstm_stack = nn.LSTM(input_size=10,\n",
    "                     hidden_size=10,\n",
    "                     num_layers=3) # 3 single LSTM cells stacked on top of each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e421579e-ab99-4b5f-be73-2a7f11f70d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a single GRU cell\n",
    "gru_cell = nn.GRUCell(input_size=10, # can adjust as necessary\n",
    "                      hidden_size=10) # can adjust as necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "083284c1-501a-466a-b4e9-901a079f958c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack together GRU cells\n",
    "gru_stack = nn.GRU(input_size=10, \n",
    "                   hidden_size=10,\n",
    "                   num_layers=3) # 3 single GRU cells stacked on top of each other "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5087611c-aae7-41fe-8397-03e01c885ade",
   "metadata": {},
   "source": [
    "### 激活函数\n",
    "\n",
    "[激活函数](https://en.wikipedia.org/wiki/Activation_function)通常位于神经网络的层与层之间，为线性（直线）函数添加非线性（非直线）能力。\n",
    "\n",
    "本质上，神经网络通常由大量的线性和非线性函数组成。\n",
    "\n",
    "PyTorch 在 `torch.nn` 中内置了[多种非线性激活函数](https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity)。\n",
    "\n",
    "其中一些最常见的包括：\n",
    "* `nn.ReLU` - 也称为[修正线性单元](https://en.wikipedia.org/wiki/Rectifier_(neural_networks))。\n",
    "* `nn.Sigmoid` - 也称为[Sigmoid 函数](https://en.wikipedia.org/wiki/Sigmoid_function)。\n",
    "* `nn.Softmax` - 也称为[Softmax 函数](https://en.wikipedia.org/wiki/Softmax_function)。\n",
    "\n",
    "> **注意：** 更多信息请参见 [02. PyTorch 神经网络分类部分 6：非线性，缺失的一环](https://www.learnpytorch.io/02_pytorch_classification/#6-the-missing-piece-non-linearity)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "38581ec6-ed57-4c2f-89bb-f99193939cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReLU\n",
    "relu = nn.ReLU()\n",
    "\n",
    "# Sigmoid\n",
    "sigmoid = nn.Sigmoid()\n",
    "\n",
    "# Softmax\n",
    "softmax = nn.Softmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf38e1c3-1159-439d-ad3b-0db1b7fa3d12",
   "metadata": {},
   "source": [
    "### 损失函数\n",
    "\n",
    "损失函数衡量你的模型有多*错误*。换句话说，它的预测与正确值相差多远。\n",
    "\n",
    "理想情况下，通过训练、数据和优化函数，这个损失值会尽可能降低。\n",
    "\n",
    "在 PyTorch（以及深度学习一般）中，损失函数也常被称为：准则、成本函数。\n",
    "\n",
    "PyTorch 在 `torch.nn` 中内置了[多种损失函数](https://pytorch.org/docs/stable/nn.html#loss-functions)。\n",
    "\n",
    "其中一些最常见的包括：\n",
    "* [`nn.L1Loss`](https://pytorch.org/docs/stable/generated/torch.nn.L1Loss.html#torch.nn.L1Loss) - 也称为 MAE 或[平均绝对误差](https://en.wikipedia.org/wiki/Mean_absolute_error)（这种损失常用于回归问题或预测数值，如房价）。\n",
    "* [`nn.MSELoss`](https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html#torch.nn.MSELoss) - 也称为 L2Loss 或[均方误差](https://en.wikipedia.org/wiki/Mean_squared_error)（这种损失常用于回归问题或预测数值，如房价）。\n",
    "* [`nn.BCEWithLogitsLoss`](https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html#torch.nn.BCEWithLogitsLoss) - 也称为[二元交叉熵](https://en.wikipedia.org/wiki/Cross_entropy)，这种损失函数常用于二元分类问题（将事物分类为是或否）。\n",
    "* [`nn.CrossEntropyLoss`](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss) - 这种损失函数常用于多类别分类问题（将事物分类为多个类别之一）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7ffe3146-759e-4f2f-aeea-ec1ecb506ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L1Loss\n",
    "loss_fn = nn.L1Loss() # also known as MAE or mean absolute error\n",
    "\n",
    "# MSELoss\n",
    "loss_fn = nn.MSELoss() # also known as MSE or mean squared error\n",
    "\n",
    "# Binary cross entropy (for binary classification problems)\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Cross entropy (for multi-class classification problems)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5746cf2-2ff9-4621-a681-df36cac3beb1",
   "metadata": {},
   "source": [
    "### 优化器\n",
    "\n",
    "优化器的工作是调整神经网络的权重，以减少损失函数的值。\n",
    "\n",
    "PyTorch 在 `torch.optim` 模块中内置了[多种优化函数](https://pytorch.org/docs/stable/optim.html)。\n",
    "\n",
    "主要的优化器函数包括：\n",
    "* [`torch.optim.SGD(lr=0.1, params=model.parameters())`](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD) - SGD，即[随机梯度下降](https://en.wikipedia.org/wiki/Stochastic_gradient_descent)（`lr` 表示“学习率”，即每次调整神经网络权重的倍数，小值 = 小调整，大值 = 大调整）。\n",
    "* [`torch.optim.Adam(lr=0.001, params=model.parameters())`](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam) - Adam 优化器（`params` 表示“模型参数”，即在训练过程中希望优化函数优化的模型参数/权重）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e6ec2382-d11d-40d4-afb7-fec01f4abccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a baseline model\n",
    "model = nn.Transformer()\n",
    "\n",
    "# SGD (stochastic gradient descent)\n",
    "optimizer = torch.optim.SGD(lr=0.1, # set the learning rate (required)\n",
    "                            params=model.parameters()) # tell the optimizer what parameters to optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "75a27e05-12fe-42f1-83aa-1e488f594373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a baseline model\n",
    "model = nn.Transformer()\n",
    "\n",
    "# Adam optimizer\n",
    "optimizer = torch.optim.Adam(lr=0.001, # set the learning rate (required)\n",
    "                             params=model.parameters()) # tell the optimizer what parameters to optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4bef22-4a74-487e-b8c6-18cb90bb0964",
   "metadata": {},
   "source": [
    "## 端到端示例工作流程\n",
    "\n",
    "让我们将所有内容整合到一个快速的端到端工作流程中。\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/01_a_pytorch_workflow.png\" width=950 alt=\"从数据到构建模型，再到拟合模型，最后评估模型的PyTorch工作流程\"/> \n",
    "\n",
    "此工作流程摘自 [01. PyTorch 工作流程基础](https://www.learnpytorch.io/01_pytorch_workflow/)。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24805c73-7558-4d27-aba1-a78fce5312ce",
   "metadata": {},
   "source": [
    "### 创建数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7fed19d7-0e4e-42e8-ad80-8504033b3f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0000],\n",
       "         [0.0200],\n",
       "         [0.0400],\n",
       "         [0.0600],\n",
       "         [0.0800],\n",
       "         [0.1000],\n",
       "         [0.1200],\n",
       "         [0.1400],\n",
       "         [0.1600],\n",
       "         [0.1800]]),\n",
       " tensor([[0.3000],\n",
       "         [0.3140],\n",
       "         [0.3280],\n",
       "         [0.3420],\n",
       "         [0.3560],\n",
       "         [0.3700],\n",
       "         [0.3840],\n",
       "         [0.3980],\n",
       "         [0.4120],\n",
       "         [0.4260]]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create *known* parameters\n",
    "weight = 0.7\n",
    "bias = 0.3\n",
    "\n",
    "# Create data\n",
    "start = 0\n",
    "end = 1\n",
    "step = 0.02\n",
    "X = torch.arange(start, end, step).unsqueeze(dim=1) # data\n",
    "y = weight * X + bias # labels (want model to learn from data to predict these)\n",
    "\n",
    "X[:10], y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7dbfae76-edbf-470b-8686-8e12e30bbc8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40, 10, 10)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create train/test split\n",
    "train_split = int(0.8 * len(X)) # 80% of data used for training set, 20% for testing \n",
    "X_train, y_train = X[:train_split], y[:train_split]\n",
    "X_test, y_test = X[train_split:], y[train_split:]\n",
    "\n",
    "len(X_train), len(y_train), len(X_test), len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b525ca1-bcc3-48c9-8b6b-ead556a50e9c",
   "metadata": {},
   "source": [
    "### 创建模型\n",
    "\n",
    "在 PyTorch 中创建模型的两种主要方式：\n",
    "1. 子类化 `torch.nn.Module` - 代码较多但非常灵活，子类化 `torch.nn.Module` 的模型必须实现 `forward()` 方法。\n",
    "2. 使用 `torch.nn.Sequential` - 代码较少但灵活性较低。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0f102f8c-ad12-48b4-bfc6-bde5eb945bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LinearRegressionModel(\n",
       "   (linear_layer): Linear(in_features=1, out_features=1, bias=True)\n",
       " ),\n",
       " OrderedDict([('linear_layer.weight', tensor([[0.5025]])),\n",
       "              ('linear_layer.bias', tensor([-0.0722]))]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "# Option 1 - subclass torch.nn.Module\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Use nn.Linear() for creating the model parameters\n",
    "        self.linear_layer = nn.Linear(in_features=1, \n",
    "                                      out_features=1)\n",
    "    \n",
    "    # Define the forward computation (input data x flows through nn.Linear())\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.linear_layer(x)\n",
    "\n",
    "model_0 = LinearRegressionModel()\n",
    "model_0, model_0.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb37ecd4-6258-404d-8dc3-149cd8540af3",
   "metadata": {},
   "source": [
    "现在让我们使用 `torch.nn.Sequential` 创建与上面相同的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e2c357fd-68ef-428e-90ae-ed225dad2e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Sequential(\n",
       "   (0): Linear(in_features=1, out_features=1, bias=True)\n",
       " ),\n",
       " OrderedDict([('0.weight', tensor([[0.9905]])), ('0.bias', tensor([0.9053]))]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "# Option 2 - use torch.nn.Sequential\n",
    "model_1 = torch.nn.Sequential(\n",
    "    nn.Linear(in_features=1,\n",
    "              out_features=1))\n",
    "\n",
    "model_1, model_1.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11692983-6190-4d51-9d4e-5293f4205988",
   "metadata": {},
   "source": [
    "### 设置损失函数和优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5c3d1c6d-a60f-4642-994d-7e0cb822164b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create loss function\n",
    "loss_fn = nn.L1Loss()\n",
    "\n",
    "# Create optimizer\n",
    "optimizer = torch.optim.SGD(params=model_1.parameters(), # optimize newly created model's parameters\n",
    "                            lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b2f55e-8037-4942-8b74-0a09a3f4b007",
   "metadata": {},
   "source": [
    "### 创建训练/测试循环\n",
    "\n",
    "我们的目标是减少模型的损失（即模型的预测与实际数据之间的差异）。\n",
    "\n",
    "如果我们的训练/测试循环实现正确，并且模型能够学习数据中的模式，那么训练和测试损失应该会下降。\n",
    "\n",
    "以下是PyTorch训练循环的步骤：\n",
    "* [PyTorch优化循环歌曲](https://youtu.be/Nutpusq_AFw)\n",
    "* [PyTorch工作流程基础 第3节：训练循环](https://www.learnpytorch.io/01_pytorch_workflow/#pytorch-training-loop)\n",
    "* [PyTorch工作流程基础 第3节：测试循环](https://www.learnpytorch.io/01_pytorch_workflow/#pytorch-testing-loop)\n",
    "* [PyTorch工作流程基础 第6.3节：训练](https://www.learnpytorch.io/01_pytorch_workflow/#63-training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0064882b-5fc7-4479-ad81-0dc0686ea711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Train loss: 0.008362661115825176 | Test loss: 0.005596190690994263\n",
      "Epoch: 100 | Train loss: 0.008362661115825176 | Test loss: 0.005596190690994263\n",
      "Epoch: 200 | Train loss: 0.008362661115825176 | Test loss: 0.005596190690994263\n",
      "Epoch: 300 | Train loss: 0.008362661115825176 | Test loss: 0.005596190690994263\n",
      "Epoch: 400 | Train loss: 0.008362661115825176 | Test loss: 0.005596190690994263\n",
      "Epoch: 500 | Train loss: 0.008362661115825176 | Test loss: 0.005596190690994263\n",
      "Epoch: 600 | Train loss: 0.008362661115825176 | Test loss: 0.005596190690994263\n",
      "Epoch: 700 | Train loss: 0.008362661115825176 | Test loss: 0.005596190690994263\n",
      "Epoch: 800 | Train loss: 0.008362661115825176 | Test loss: 0.005596190690994263\n",
      "Epoch: 900 | Train loss: 0.008362661115825176 | Test loss: 0.005596190690994263\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Set the number of epochs \n",
    "epochs = 1000 \n",
    "\n",
    "# Put data on the available device\n",
    "# Without this, an error will happen (not all data on target device)\n",
    "X_train = X_train.to(device)\n",
    "X_test = X_test.to(device)\n",
    "y_train = y_train.to(device)\n",
    "y_test = y_test.to(device)\n",
    "\n",
    "# Put model on the available device\n",
    "# With this, an error will happen (the model is not on target device)\n",
    "model_1 = model_1.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    ### Training\n",
    "    model_1.train() # train mode is on by default after construction\n",
    "\n",
    "    # 1. Forward pass\n",
    "    y_pred = model_1(X_train)\n",
    "\n",
    "    # 2. Calculate loss\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "\n",
    "    # 3. Zero grad optimizer\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 4. Loss backward\n",
    "    loss.backward()\n",
    "\n",
    "    # 5. Step the optimizer\n",
    "    optimizer.step()\n",
    "\n",
    "    ### Testing\n",
    "    model_1.eval() # put the model in evaluation mode for testing (inference)\n",
    "    # 1. Forward pass\n",
    "    with torch.inference_mode():\n",
    "        test_pred = model_1(X_test)\n",
    "    \n",
    "        # 2. Calculate the loss\n",
    "        test_loss = loss_fn(test_pred, y_test)\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch: {epoch} | Train loss: {loss} | Test loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af70942c-b2de-47ae-a266-d8097a124600",
   "metadata": {},
   "source": [
    "## 额外资源\n",
    "\n",
    "上述列表并不详尽。\n",
    "\n",
    "以下是一些了解更多信息的好地方：\n",
    "\n",
    "* [PyTorch 官方速查表](https://pytorch.org/tutorials/beginner/ptcheat.html)。\n",
    "* [Zero to Mastery 学习 PyTorch 课程](https://dbourke.link/ZTMPyTorch) - 一个全面且适合初学者的深入课程，从基础知识到将模型部署到现实世界中供他人使用。\n",
    "* [PyTorch 性能调优指南](https://pytorch.org/tutorials/recipes/recipes/tuning_guide.html) - PyTorch 团队提供的关于如何调优 PyTorch 模型性能的资源。\n",
    "* [PyTorch 额外资源](https://www.learnpytorch.io/pytorch_extra_resources/) - 一个精心挑选的有助于扩展 PyTorch 并了解更多深度学习工程方面的资源列表。\n",
    "* [Effective PyTorch by vahidk](https://github.com/vahidk/EffectivePyTorch) - 一个 GitHub 仓库，以直接的方式概述了 PyTorch 的一些主要功能。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
